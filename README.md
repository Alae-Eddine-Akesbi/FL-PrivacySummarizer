# ğŸš€ Federated Privacy-Preserving Summarization Platform

## ğŸ“‹ Vue d'ensemble

Plateforme industrielle de rÃ©sumÃ© de documents longs utilisant le Federated Learning pour prÃ©server la confidentialitÃ© des donnÃ©es. Trois dÃ©partements (SantÃ©, Finance, Juridique) collaborent pour entraÃ®ner un modÃ¨le sans partager leurs donnÃ©es sensibles.

## ğŸ—ï¸ Architecture du Projet

```
project/
â”œâ”€â”€ README.md                           # Documentation principale
â”œâ”€â”€ requirements.txt                    # DÃ©pendances Python
â”œâ”€â”€ docker-compose.yml                  # Orchestration des services
â”œâ”€â”€ .env.example                        # Variables d'environnement template
â”‚
â”œâ”€â”€ configs/                            # Configuration centralisÃ©e
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model_config.py                 # Configuration du modÃ¨le LED
â”‚   â”œâ”€â”€ federated_config.py             # ParamÃ¨tres FedProx & FL
â”‚   â””â”€â”€ kafka_config.py                 # Configuration Kafka
â”‚
â”œâ”€â”€ data_ingestion/                     # Phase 1: Ingestion Kafka
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ producer.py                     # Single Producer robuste
â”‚   â”œâ”€â”€ topic_manager.py                # Gestion des topics Kafka
â”‚   â””â”€â”€ data_loader.py                  # Chargement des datasets
â”‚
â”œâ”€â”€ federated_learning/                 # CÅ“ur du systÃ¨me FL
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ flower_client.py                # FlowerClient avec FedProx + LoRA
â”‚   â”œâ”€â”€ flower_server.py                # StratÃ©gie d'agrÃ©gation personnalisÃ©e
â”‚   â”œâ”€â”€ fedprox_optimizer.py            # ImplÃ©mentation FedProx
â”‚   â””â”€â”€ lora_manager.py                 # Gestion PEFT/LoRA
â”‚
â”œâ”€â”€ model/                              # Gestion du modÃ¨le
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ led_summarizer.py               # Wrapper pour LED avec global_attention
â”‚   â”œâ”€â”€ model_loader.py                 # Chargement + Quantification 4-bit
â”‚   â””â”€â”€ tokenizer_utils.py              # Utilitaires de tokenization
â”‚
â”œâ”€â”€ evaluation/                         # MÃ©triques et Ã©valuation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py                      # ROUGE + BERTScore
â”‚   â”œâ”€â”€ aggregator.py                   # AgrÃ©gation des mÃ©triques globales
â”‚   â””â”€â”€ evaluator.py                    # Pipeline d'Ã©valuation
â”‚
â”œâ”€â”€ utils/                              # Utilitaires transversaux
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ checkpoint_manager.py           # Sauvegarde/Reprise LoRA
â”‚   â”œâ”€â”€ kafka_offset_manager.py         # Gestion des offsets Kafka
â”‚   â”œâ”€â”€ logger.py                       # Logging structurÃ©
â”‚   â””â”€â”€ helpers.py                      # Fonctions auxiliaires
â”‚
â”œâ”€â”€ monitoring/                         # Dashboard & Visualisation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ streamlit_dashboard.py          # Interface Streamlit
â”‚   â”œâ”€â”€ metrics_collector.py            # Collecte des mÃ©triques
â”‚   â””â”€â”€ visualization.py                # GÃ©nÃ©ration des graphiques
â”‚
â”œâ”€â”€ inference/                          # Phase 2: InfÃ©rence temps rÃ©el
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ kafka_consumer.py               # Consumer pour infÃ©rence
â”‚   â””â”€â”€ inference_pipeline.py           # Pipeline de rÃ©sumÃ©
â”‚
â”œâ”€â”€ docker/                             # Dockerfiles et scripts
â”‚   â”œâ”€â”€ Dockerfile.client               # Image pour Flower Client
â”‚   â”œâ”€â”€ Dockerfile.server               # Image pour Flower Server
â”‚   â”œâ”€â”€ Dockerfile.producer             # Image pour Producer
â”‚   â”œâ”€â”€ Dockerfile.dashboard            # Image pour Dashboard
â”‚   â””â”€â”€ entrypoint.sh                   # Script d'initialisation
â”‚
â”œâ”€â”€ scripts/                            # Scripts d'automatisation
â”‚   â”œâ”€â”€ setup_kafka_topics.sh           # CrÃ©ation des topics
â”‚   â”œâ”€â”€ run_training.sh                 # Lancement de l'entraÃ®nement
â”‚   â””â”€â”€ test_inference.sh               # Test du pipeline d'infÃ©rence
â”‚
â”œâ”€â”€ notebooks/                          # Analyse pÃ©dagogique
â”‚   â””â”€â”€ analysis_and_theory.ipynb       # Notebook Jupyter complet
â”‚
â””â”€â”€ tests/                              # Tests unitaires
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_producer.py
    â”œâ”€â”€ test_client.py
    â””â”€â”€ test_metrics.py
```

## ğŸ¯ Les 11 Piliers Techniques

### 1ï¸âƒ£ ModÃ¨le: LED Large Book Summary
- **ModÃ¨le**: `pszemraj/led-large-book-summary`
- **Global Attention**: Gestion automatique du masque d'attention sur `<s>`
- **CapacitÃ©**: Textes jusqu'Ã  16,384 tokens

### 2ï¸âƒ£ Algorithmes: FedProx + LoRA
- **FedProx**: Terme de pÃ©nalitÃ© proximale Âµ = 0.01
- **PEFT/LoRA**: Adapters rank=16, alpha=32
- **Optimisation**: RÃ©duction de 99% des paramÃ¨tres entraÃ®nables

### 3ï¸âƒ£ Infrastructure Streaming (Kafka)
- **Phase 1 (Fine-tuning)**: 3 topics dÃ©diÃ©s (health, finance, legal)
- **Phase 2 (InfÃ©rence)**: Pipeline temps rÃ©el
- **RÃ©silience**: Gestion des offsets + replay

### 4ï¸âƒ£ Dynamique de Training
- **Steps fixes**: 50 pas par round
- **Ã‰quilibrage**: Distribution uniforme entre clients
- **Convergence**: 10 rounds globaux

### 5ï¸âƒ£ Datasets (20k lignes/client)
| Client | Dataset | Topic Kafka |
|--------|---------|-------------|
| SantÃ© | `ccdv/pubmed-summarization` | `health-documents` |
| Finance | `mrSoul7766/ECTSum` | `finance-documents` |
| Juridique | `FiscalNote/billsum` | `legal-documents` |

### 6ï¸âƒ£ Ã‰valuation
- **MÃ©triques**: ROUGE-1, ROUGE-2, ROUGE-L, BERTScore
- **Calcul**: Local (par client) + AgrÃ©gation globale
- **FrÃ©quence**: AprÃ¨s chaque round

### 7ï¸âƒ£ RÃ©silience
- **Checkpoints LoRA**: Sauvegarde aprÃ¨s chaque round
- **Offsets Kafka**: Commit automatique post-traitement
- **Reprise**: RÃ©cupÃ©ration complÃ¨te de l'Ã©tat

### 8ï¸âƒ£ Monitoring
- **Dashboard Streamlit**: Courbes de loss en temps rÃ©el
- **Interface de test**: RÃ©sumÃ© interactif
- **MÃ©triques**: Visualisation des performances

### 9ï¸âƒ£ Orchestration Docker
```
Services:
â”œâ”€â”€ zookeeper          # Coordination Kafka
â”œâ”€â”€ kafka              # Message broker
â”œâ”€â”€ flower-server      # Serveur Flower
â”œâ”€â”€ health-client      # Client SantÃ©
â”œâ”€â”€ finance-client     # Client Finance
â”œâ”€â”€ legal-client       # Client Juridique
â”œâ”€â”€ producer           # Ingestion des donnÃ©es
â””â”€â”€ dashboard          # Interface Streamlit
```

### ğŸ”Ÿ Ingestion Intelligente
- **Single Producer**: Un seul point d'entrÃ©e
- **Routage**: Distribution vers 3 topics selon le type
- **Robustesse**: Retry automatique + gestion d'erreurs

### 1ï¸âƒ£1ï¸âƒ£ Approche Hybride
- **Production**: Scripts `.py` modulaires
- **PÃ©dagogie**: Notebook `.ipynb` avec thÃ©orie

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
```bash
- Docker & Docker Compose
- Python 3.9+
- CUDA 11.8+ (pour GPU)
- 16GB RAM minimum
```

### Installation

1. **Cloner et configurer**
```bash
cd project
cp .env.example .env
# Ã‰diter .env avec vos paramÃ¨tres
```

2. **Lancer l'infrastructure**
```bash
docker-compose up -d
```

3. **VÃ©rifier les logs**
```bash
docker-compose logs -f flower-server
```

4. **AccÃ©der au dashboard**
```
http://localhost:8501
```

## ğŸ“Š Utilisation

### Phase 1: Fine-tuning FÃ©dÃ©rÃ©

1. **Ingestion des donnÃ©es**
```bash
docker-compose exec producer python data_ingestion/producer.py
```

2. **Lancement de l'entraÃ®nement**
```bash
docker-compose exec flower-server python federated_learning/flower_server.py
```

3. **Monitoring**
- Dashboard: http://localhost:8501
- Flower UI: http://localhost:8080

### Phase 2: InfÃ©rence Temps RÃ©el

```bash
docker-compose exec dashboard python inference/inference_pipeline.py
```

## ğŸ”§ Configuration

### Variables d'environnement (.env)

```bash
# Kafka
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
KAFKA_HEALTH_TOPIC=health-documents
KAFKA_FINANCE_TOPIC=finance-documents
KAFKA_LEGAL_TOPIC=legal-documents

# Flower
FLOWER_SERVER_ADDRESS=flower-server:8080
NUM_ROUNDS=10
STEPS_PER_ROUND=50

# Model
MODEL_NAME=pszemraj/led-large-book-summary
MAX_INPUT_LENGTH=8192
MAX_TARGET_LENGTH=512
LOAD_IN_4BIT=true

# FedProx
FEDPROX_MU=0.01
LEARNING_RATE=2e-5

# LoRA
LORA_R=16
LORA_ALPHA=32
LORA_DROPOUT=0.05
```

## ğŸ“ˆ MÃ©triques et Performance

### Attendues aprÃ¨s convergence:
- **ROUGE-1**: ~0.45
- **ROUGE-2**: ~0.22
- **ROUGE-L**: ~0.38
- **BERTScore F1**: ~0.85

### Optimisations VRAM:
- **Quantification 4-bit**: ~8GB VRAM par client
- **Gradient Checkpointing**: ActivÃ©
- **LoRA**: 0.5% des paramÃ¨tres

## ğŸ›¡ï¸ SÃ©curitÃ© et ConfidentialitÃ©

- âœ… **Aucun partage de donnÃ©es brutes**
- âœ… **AgrÃ©gation sÃ©curisÃ©e des gradients**
- âœ… **Isolation des clients (Docker)**
- âœ… **Chiffrement des communications (TLS possible)**

## ğŸ“š Documentation Technique

Voir le notebook `notebooks/analysis_and_theory.ipynb` pour:
- Explication thÃ©orique du Federated Learning
- DÃ©tails sur FedProx vs FedAvg
- Analyse des rÃ©sultats
- Visualisations avancÃ©es

## ğŸ¤ Contribution

Ce projet suit les standards:
- **Type Hints**: Obligatoires
- **Docstrings**: Style Google
- **Tests**: Coverage > 80%
- **Linting**: Black + Flake8

## ğŸ“„ Licence

MIT License - Voir LICENSE file

## ğŸ‘¥ Contact

Pour toute question ou support, contacter l'Ã©quipe AI Solutions Architecture.

---

**Version**: 1.0.0  
**DerniÃ¨re mise Ã  jour**: DÃ©cembre 2024  
**Status**: Production Ready âœ…
